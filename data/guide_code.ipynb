## **24-2학기 가이드 프로젝트**


*   가이드 코드에는 이상치 처리, 수치형 변수 정규화/표준화, 하이퍼파라미터 튜닝, feature selection 등이 생략되어 있습니다. 해당 부분들 중 필요하다고 생각하는 부분을 직접 수행해보세요
*   가이드 코드는 어디까지나 참고용입니다. 꼭 가이드 코드대로 프로젝트를 수행할 필요는 없으니 팀별로 자유롭게 프로젝트를 진행해주세요 :)


#코랩 환경에서 실행
from google.colab import drive
drive.mount('/content/drive')
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# train/test 데이터 가져오기
train_df = pd.read_csv('/content/train_data.csv')
train_df.head()
#test 데이터 가져오기
test_df = pd.read_csv('/content/test_data.csv')
test_df.head()
## 데이터 전처리 - 결측값
train_df.info()
test_df.info()
#test data에 결측치 없음
#train data에서 결측치가 존재하는 행 확인
train_df[train_df.isna().sum(axis=1) > 0]
#결측치가 존재하는 행의 고유한 값 확인
print(train_df['workclass'].unique())
print()
print(train_df['occupation'].unique())
print()
print(train_df['native.country'].unique())
#결측행 삭제
train_df_cleaned = train_df.dropna()
#결측치 제거 확인
train_df_cleaned.isna().sum()
#결측치 없어진 train/test dataset
train = train_df_cleaned.copy(deep=True)
test = test_df.copy(deep=True)
train.shape
## 데이터 분포 시각화
#target column의 value가 <=50k인 데이터 수와 >=50인 데이터 수 비교
counted_values = train['income'].value_counts()
plt.style.use('ggplot')
plt.figure(figsize=(12, 10))
plt.title('class counting', fontsize = 30)
value_bar_ax = sns.barplot(x=counted_values.index, y=counted_values)
value_bar_ax.tick_params(labelsize=20)
#범주형 변수 시각화를 위한 데이터 생성
train_categori = train.drop(['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week'],axis = 1) #범주형이 아닌 피쳐 drop
train_categori.head()
# 범주형 데이터 분포 확인
def visualize(axx, field, num): ##그래프를 그리기 위한 메소드
    sns.countplot(x=train_categori.columns[num], data= train_categori[train_categori['income'] == field],  color='#eaa18a', ax = axx) # countplot을 이용하여 그래프를 그려줍니다. # x 인자를 명시적으로 추가
    axx.set_title(field)

figure, ((ax1,ax2),(ax3,ax4), (ax5, ax6),(ax7, ax8), (ax9, ax10),
         (ax11,ax12),(ax13,ax14), (ax15, ax16))  = plt.subplots(nrows=8, ncols=2) ## 원하는 개수의 subplots 만들어주기
figure.set_size_inches(40, 50) #(w,h)
figure.suptitle('Compare categorical features', fontsize=40, y = 0.9)

k = 0 # 피쳐 수
j = 1 # 그래프 수
while k<8:
    for i in range(0,2):
        visualize(eval(f'ax{j}'), train_categori['income'].unique()[i], k)
        j = j+1
    k = k+1
# 수치형 변수 데이터를 확인하기 위한 데이터 생성
train_numeric = train[['age', 'fnlwgt', 'capital.gain', 'capital.loss', 'hours.per.week', 'income']] #수치형 피쳐와 label인 target 추출
train_numeric.head()

#수치형 변수 데이터의 통계 확인
train_numeric.describe()
# 수치형 데이터 분포
def visualize(axx, field, num):
    line = train_numeric[train_numeric['income'] == field] #메소드에서 target 클래스 추춣
    name = train_numeric[train_numeric['income'] == field][train_numeric.columns[num]].name #메소드에서 이름 추출
    sns.kdeplot(x = line[train_numeric.columns[num]],  data = train_numeric, ax = axx, color='#eaa18a') #countplot을 이용하여 그래프를 그려준다
    axx.axvline(line.describe()[name]['mean'], c='#f55354', label = f"mean = {round(line.describe()[name]['mean'], 2)}") #mean 통계값을 표기
    axx.axvline(line.describe()[name]['50%'], c='#518d7d', label = f"median = {round(line.describe()[name]['50%'], 2)}") #median 통계값을 표기
    axx.legend()
    axx.set_title(field)

figure, ((ax1,ax2),(ax3,ax4), (ax5, ax6),(ax7, ax8), (ax9, ax10))  = plt.subplots(nrows=5, ncols=2) ##원하는 개수의 subplots 만들어주기
figure.set_size_inches(40, 50) #(w,h)
figure.suptitle('Compare numeric features', fontsize=40, y = 0.9)

k = 0 # 피쳐 수
j = 1 # 그래프 수
while k<5:
    for i in range(0,2):
        visualize(eval(f'ax{j}'), train_numeric['income'].unique()[i], k)
        j = j+1
    k = k+1
# 수치형 변수 상관 관계 확인
corr_df = train_numeric.corr()

# 사이즈 조정
sns.set(rc={'figure.figsize':(11.7,8.27)})

# 절반만 표시하기 위한 mask 설정
mask=np.zeros_like(corr_df)
mask[np.triu_indices_from(mask)]=True

ax = sns.heatmap(corr_df,
                 annot=True, # 데이터 값 표시
                 mask=mask, # 마스크 적용 표시
                 cmap='YlOrRd') # 노랑 / 오렌지 / 빨강

plt.xticks(rotation=45)
plt.title('Relationship of cols', fontsize=20)
plt.show()
## 범주형 인코딩

머신러닝 알고리즘은 숫자형 데이터를 필요로 하므로 범주형 변수를 수치형 변수로 변환
가이드 코드에서는 label-encoding 방법을 사용
from sklearn.preprocessing import LabelEncoder
# LabelEncoder 생성 및 적용
label_encoders = {}

for column in train.select_dtypes(include=['object']).columns:
    label_encoders[column] = LabelEncoder()

    # Train 데이터를 인코딩
    train[column] = label_encoders[column].fit_transform(train[column])

    # Test 데이터를 인코딩
    test[column] = label_encoders[column].transform(test[column])

train
test
## 모델 학습

가이드 코드에서는 LogisticRegression을 예시로 보여드립니다! 다양한 모델 및 분석방법을 통해 정확도를 높여주세요!
X = train.drop(['income'], axis=1)
y = train['income']
print(X.shape, y.shape)
# 모델의 성능을 측정하기 위해서 데이터를 train 데이터와 valid 데이터로 분리
from sklearn.model_selection import train_test_split

X_train, X_valid, y_train, y_valid = train_test_split(X,
                                                      y,
                                                      test_size=0.2,
                                                      random_state=42)
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# 모델 선언
model = LogisticRegression(random_state=0)

# 모델 학습
model.fit(X_train, y_train)
pred = model.predict(X_valid)
score = accuracy_score(y_valid, pred)

print(f"LogisticRegression 모델 정확도: {score*100:.2f}%")
## 모델의 test set 성능 확인
#test score 출력을 위한 x,y 데이터 분리
test_x = test.drop('income', axis=1)
test_y = test['income']
